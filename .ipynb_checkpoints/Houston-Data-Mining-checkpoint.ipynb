{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Houston 311 Service Requests Data Mining Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group members\n",
    "Stephen Huang\n",
    "\n",
    "Levi Villarreal\n",
    "\n",
    "Joshua Wong\n",
    "\n",
    "Andrew Young\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 500)\n",
    "import time\n",
    "import datetime\n",
    "import zipfile\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data is from http://www.houstontx.gov/311/\n",
    "names = [\"CASE NUMBER\", \"SR LOCATION\", \"COUNTY\", \"DISTRICT\", \"NEIGHBORHOOD\", \"TAX ID\", \n",
    "         \"TRASH QUAD\", \"RECYCLE QUAD\", \"TRASH DAY\", \"HEAVY TRASH DAY\", \"RECYCLE DAY\", \n",
    "         \"KEY MAP\", \"MANAGEMENT DISTRICT\", \"DEPARTMENT\", \"DIVISION\", \"SR TYPE\", \"QUEUE\", \n",
    "         \"SLA\", \"STATUS\", \"SR CREATE DATE\", \"DUE DATE\", \"DATE CLOSED\", \"OVERDUE\", \"TITLE\", \n",
    "         \"x\", \"y\", \"LATITUDE\", \"LONGITUDE\", \"CHANNEL TYPE\"]\n",
    "\n",
    "with zipfile.ZipFile(\"311-Public-Data-Extract-2018-clean.txt.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"\")\n",
    "\n",
    "data = pd.read_csv('311-Public-Data-Extract-2018-clean.txt', sep=\"|\", header=None, names=names)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "Right off the bat, we can see that there are many features that do not matter at all to our project.\n",
    "We can go ahead and get rid of these to help prevent against the curse of dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['SR LOCATION', 'CASE NUMBER', 'TRASH QUAD', 'RECYCLE QUAD', 'TRASH DAY', 'HEAVY TRASH DAY', 'RECYCLE DAY', 'TAX ID', 'KEY MAP', 'DUE DATE', 'DATE CLOSED', 'TITLE', 'x', 'y', 'LONGITUDE', 'LATITUDE'])\n",
    "print(data.shape)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reasoning behind dropping the attributes we did\n",
    "\n",
    "SR Location - Same reasoning as case number.\n",
    "\n",
    "Case number - This was dropped because the case number is a unique identifier assigned to every 311 request, and thus could not be used to classify anything.\n",
    "\n",
    "Trash Quad - There are requests that are not related to trash collection. Those requests might be misclassified because they are in a different trash quad as other requests in the dataset.\n",
    "\n",
    "Recycle Quad - Same as Trash Quad\n",
    "\n",
    "Trash Day - Same as Trash Quad\n",
    "\n",
    "Recycle day - Same as Trash Quad\n",
    "\n",
    "Heavy Trash Day - Same as Trash Quad\n",
    " \n",
    "Tax ID - This ID is unique to the property that requested it.\n",
    " \n",
    "Key Map - This attribute is used in the cities internal system to keep track of requests and does not have any actual relation to the request\n",
    " \n",
    "Due Date - We are interested in predicting overdueness, and that it its own seperate column.\n",
    " \n",
    "Date Closed - Same reasoning as due date.\n",
    " \n",
    "Title - This is a another unique identifier assigned to every 311 request, and thus could not be used to classify anything.\n",
    " \n",
    "x - We already have latitude, and this attribute an approximation of latitude.\n",
    " \n",
    "y - We already have longitude, and this attribute an approximation of longitude.\n",
    "\n",
    "latitude - This is too speficific for our needs, and we have other location metrics.\n",
    " \n",
    "longitude - same as latitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all service requests that are not closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldNumRows = data.shape[0]\n",
    "data = data[data.STATUS == 'Closed']\n",
    "data = data.drop([\"STATUS\"], axis=1)\n",
    "\n",
    "print(\"Number of rows dropped: \", oldNumRows - data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize all counties and drop rows where county is unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Counties:')\n",
    "print(data['COUNTY'].value_counts())\n",
    "print()\n",
    "\n",
    "oldNumRows = data.shape[0]\n",
    "data['COUNTY'] = data['COUNTY'].replace(['HARRIS', 'FORT BEND', 'MONTGOMERY'], ['Harris County', 'Fort Bend County', 'Montgomery County'])\n",
    "data = data[data.COUNTY != 'Unknown']\n",
    "\n",
    "print('Counties:')\n",
    "print(data['COUNTY'].value_counts())\n",
    "print()\n",
    "print(\"Number of rows with COUNTY == 'Unknown' dropped: \", oldNumRows - data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows where district is unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldNumRows = data.shape[0]\n",
    "data = data[data.DISTRICT != 'Unknown']\n",
    "\n",
    "print(\"Number of rows dropped: \", oldNumRows - data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize all districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['MANAGEMENT DISTRICT'] = data['MANAGEMENT DISTRICT'].replace(['HCID #3 TRACT 19 (Upper Kirby)', 'HCID #3 TRACT 47 (Upper Kirby)', 'East End MD', 'Greater Northside', 'Sharpstown'], ['HCID #3 (Upper Kirby)', 'HCID #3 (Upper Kirby)', 'East End', 'Greater Northside MD', 'Sharpstown MD'])\n",
    "print('Management Districts:')\n",
    "print(data['MANAGEMENT DISTRICT'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all rows with unknown channel types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldNumRows = data.shape[0]\n",
    "data = data[data['CHANNEL TYPE'] != 'Unknown']\n",
    "\n",
    "print(\"Number of rows dropped: \", oldNumRows - data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldNumRows = data.shape[0]\n",
    "data = data.dropna()\n",
    "\n",
    "print(\"Number of rows dropped: \", oldNumRows - data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the request date would be draw conclusions from, so we transformed the feature to instead be the month in which the service request was created, to account seasonal differences in service request time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "data['SR CREATE DATE'] = data['SR CREATE DATE'].apply(lambda x : datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "data['SR CREATE DATE'] = data['SR CREATE DATE'].apply(lambda x : months[x.month-1])\n",
    "\n",
    "data = data.rename(columns={'SR CREATE DATE': 'SR MONTH'})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the overdue is continuous, which makes it hard to use in classification algorithms. To combat this, we want to bin the values, so that there are only a few possible values.\n",
    "\n",
    "The values we want bin into are on time tasks (negative values), tasks done within a week past due date (0 < x < 7), tasks done within a month past due date (7 <= x < 30), tasks done over a month past due date (x >= 30)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_overdue (val):\n",
    "    val = float(val)\n",
    "    \n",
    "    if val < 0:\n",
    "        return \"On Time\"\n",
    "    elif val < 7:\n",
    "        return \"Week\"\n",
    "    elif val < 30:\n",
    "        return \"Month\"\n",
    "    else:\n",
    "        return \"More\"\n",
    "    \n",
    "data[\"OVERDUE\"] = data[\"OVERDUE\"].apply(bin_overdue)\n",
    "    \n",
    "print(data['OVERDUE'].value_counts().sort_index())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export data to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('houston-311-sanitized.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Sanitized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('houston-311-sanitized.csv', sep=\",\", header='infer')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep the data for modeling\n",
    "\n",
    "Split the data into features and labels. The label is the overdueness of the 311 request, which we binned earlier.\n",
    "\n",
    "Because of the way that sklearn handles catagorical data, we had to encode all of the features so that they could be processed correctly.\n",
    "\n",
    "Also, we downsample the data so that the models will run quicker. We use `train_test_split` here to ensure that the downsampling is down without affecting the class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = data.copy()\n",
    "cat_columns = [\"COUNTY\", \"DISTRICT\", \"NEIGHBORHOOD\", \"MANAGEMENT DISTRICT\", \"DEPARTMENT\", \"DIVISION\",\n",
    "              \"SR TYPE\", \"QUEUE\", \"SR MONTH\", \"CHANNEL TYPE\"]\n",
    "\n",
    "for c in cat_columns:\n",
    "    prev_column = num_data[c]\n",
    "    # Transform catagorical data to one that sklearn can understand\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    num_data[c] = encoder.fit_transform(prev_column)\n",
    "\n",
    "print(num_data.head())\n",
    "train, test = train_test_split(num_data, train_size = 0.95, test_size = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "down_data = train\n",
    "\n",
    "labels = down_data['OVERDUE']\n",
    "df_features = down_data.drop(['OVERDUE'], axis=1)\n",
    "print(labels.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(df_features, labels, test_size = 0.2)\n",
    "print('Training set size:',len(labels_train))\n",
    "print('Test set size:    ',len(labels_test))\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(features_train, labels_train)\n",
    "predict_labels_test = dt.predict(features_test)\n",
    "print('Accuracy of decision tree classifier:',accuracy_score(labels_test, predict_labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = Pipeline(steps=[('scaler',StandardScaler()),('reduce_dim',PCA()),('clf',SVC(gamma='scale'))])\n",
    "param_grid = {\n",
    "    'reduce_dim__n_components': list(range(5, 11)),\n",
    "    'clf__kernel':('linear','rbf','poly')\n",
    "}\n",
    "pipedsvm = GridSearchCV(svm,param_grid,cv=5,scoring='accuracy', iid=True)\n",
    "accuracies = cross_val_score(pipedsvm.fit(df_features,labels), df_features, labels, cv=10)\n",
    "print('Official accuracy:',np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks (NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = Pipeline(steps=[('scaler',StandardScaler()),('clf',MLPClassifier())])\n",
    "param_grid = {\n",
    "    'clf__hidden_layer_sizes':((30,),(40,),(50,),(60,)),\n",
    "    'clf__activation':('logistic','tanh','relu')\n",
    "}\n",
    "pipednn = GridSearchCV(nn,param_grid,cv=5,scoring='accuracy', iid=True)\n",
    "accuracies = cross_val_score(pipednn.fit(df_features,labels), df_features, labels, cv=5)\n",
    "print('Official accuracy:',np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': list(range(1, 25))\n",
    "}\n",
    "knn = Pipeline(steps=[('scaler', StandardScaler()), ('pca', PCA()), ('knn',KNeighborsClassifier(n_neighbors=7))])\n",
    "pipedknn = GridSearchCV(knn,param_grid,cv=5,scoring='accuracy', iid=True)\n",
    "accuracies = cross_val_score(pipedknn.fit(df_features,labels), df_features, labels, cv=5)\n",
    "print('Average accuracy:',np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "Naive Bayes is not a good option for this dataset due to correlation between attributes. For example, requests from the same neighborhood would be from the same county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "accuracies = cross_val_score(nb,df_features,labels,cv=10)\n",
    "print('Average accuracy:',np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ab = AdaBoostClassifier(n_estimators=150)\n",
    "accuracies = cross_val_score(ab, df_features, labels, cv=5)\n",
    "print('Average accuracy:',np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=10)\n",
    "param_grid = {\n",
    "    'max_depth':list(range(35,55)),\n",
    "    'min_samples_leaf':(8,10,12),\n",
    "    'max_features':('sqrt','log2')\n",
    "}\n",
    "pipedrf = GridSearchCV(rf,param_grid,cv=5,scoring='accuracy', iid=True)\n",
    "accuracies = cross_val_score(pipedrf.fit(df_features,labels), df_features, labels, cv=5)\n",
    "print('Official accuracy:',np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier\n",
    "SVM, Random Forest, AdaBoost, KNN, and Neural Nets are combined in a voting classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votingclf = VotingClassifier(estimators=[('svc', pipedsvm), ('rf', rf), ('abdt', ab), ('knn', pipedknn), ('nn', pipednn)], voting='hard')\n",
    "accuracies = cross_val_score(votingclf, df_features, labels, cv=5)\n",
    "print('Average accuracy:',np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
